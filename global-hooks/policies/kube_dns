#!/bin/bash

source /deckhouse/shell_lib.sh

function __config__() {
  cat << EOF
    configVersion: v1
    kubernetes:
    - name: node_roles
      apiVersion: v1
      kind: Node
      includeSnapshotsFrom: ["node_roles", "kube_dns_autoscaler", "kube_dns"]
      jqFilter: |
        .metadata.labels // {} |
        if ([keys[] | select(startswith("node-role.flant.com/"))] | length > 0) then
          [keys[] | select(startswith("node-role.flant.com/"))][0]
        elif ([keys[] | select(startswith("node-role.deckhouse.io/"))] | length > 0) then
          [keys[] | select(startswith("node-role.deckhouse.io/"))][0]
        elif ([keys[] | select(startswith("node-role.kubernetes.io/"))] | length > 0) then
          [keys[] | select(startswith("node-role.kubernetes.io/"))][0]
        else
          null
        end |
        if . != null then
          . | split("/")[1] | gsub("-(?<a>[a-z])"; .a|ascii_upcase)
        else
          .
        end
    - name: kube_dns
      apiVersion: apps/v1
      kind: Deployment
      includeSnapshotsFrom: ["node_roles", "kube_dns_autoscaler", "kube_dns"]
      namespace:
        nameSelector:
          matchNames: [kube-system]
      labelSelector:
        matchLabels:
          k8s-app: kube-dns
    - name: kube_dns_autoscaler
      apiVersion: apps/v1
      kind: Deployment
      includeSnapshotsFrom: ["node_roles", "kube_dns_autoscaler", "kube_dns"]
      namespace:
        nameSelector:
          matchNames: [kube-system]
      labelSelector:
        matchLabels:
          k8s-app: kube-dns-autoscaler
EOF
}

function __main__() {
  count_system_nodes=$(context::jq -er '[.snapshots.node_roles[] | select(.filterResult == "system")] | length')
  count_kube_dns_nodes=$(context::jq -er '[.snapshots.node_roles[] | select(.filterResult == "kubeDns")] | length')
  count_nonspecific_nodes=$(context::jq -er '[.snapshots.node_roles[] | select(.filterResult == null)] | length')

  fltr="$(jq::include::remove_empty) ."

  ###
  # Policy #1: kube-dns must work on special nodes if they are

  if (( "$count_system_nodes" > 0 || "$count_kube_dns_nodes" > 0 )); then
    fltr=$fltr' | .spec.template.spec.tolerations = ((.spec.template.spec.tolerations // []) + [{"key":"dedicated.flant.com","operator":"Equal","value": "kube-dns"},{"key":"dedicated.flant.com","operator":"Equal","value": "system"},{"key":"node-role/system"},{"key":"node-role.kubernetes.io/master"}] | unique)'

    if (( "$count_kube_dns_nodes" > 0 )); then
      fltr=$fltr' | .spec.template.spec.affinity.nodeAffinity.requiredDuringSchedulingIgnoredDuringExecution.nodeSelectorTerms = [{"matchExpressions":[{"key":"node-role.flant.com/kube-dns","operator":"Exists"}]},{"matchExpressions":[{"key":"node-role.deckhouse.io/kube-dns","operator":"Exists"}]},{"matchExpressions":[{"key":"node-role.kubernetes.io/kube-dns","operator":"Exists"}]}]'
    else # $count_system_nodes > 0
      fltr=$fltr' | .spec.template.spec.affinity.nodeAffinity.requiredDuringSchedulingIgnoredDuringExecution.nodeSelectorTerms = [{"matchExpressions":[{"key":"node-role.flant.com/system","operator":"Exists"}]},{"matchExpressions":[{"key":"node-role.deckhouse.io/system","operator":"Exists"}]},{"matchExpressions":[{"key":"node-role.kubernetes.io/system","operator":"Exists"}]}]'
    fi
  else
    fltr=$fltr' | del(.spec.template.spec.affinity.nodeAffinity.requiredDuringSchedulingIgnoredDuringExecution.nodeSelectorTerms)'
  fi

  ###
  # policy #2: replicas
  #  * There is kube-dns-autoscaler in kops-deployed AWS and GCE. We don't want to interfere with him
  #  * In other cases:
  #    * If there are special nodes for kube-dns then deployment must fit there
  #      * If there is a single node then kube-dns must have two replicas to avoid problems with redeploy
  #    * If there are system-nodes then deployment must fit there
  #      * If there is a single node then kube-dns must have two replicas to avoid problems with redeploy
  #    * Else:
  #      * there should be 2 replicas or more if someone configured it manually
  #      * there must not be more replicas then non-specific nodes

  if ! context::has snapshots.kube_dns_autoscaler.0 ; then
    if (( "$count_kube_dns_nodes" > 1 )); then
      fltr=$fltr' | .spec.replicas = '$count_kube_dns_nodes
    elif (( "$count_kube_dns_nodes" == 1 )); then
      fltr=$fltr' | .spec.replicas = 2'
    elif (( "$count_system_nodes" > 1 )); then
      fltr=$fltr' | .spec.replicas = '$count_system_nodes
    elif (( "$count_system_nodes" == 1 )); then
      fltr=$fltr' | .spec.replicas = 2'
    else
      fltr=$fltr' | .spec.replicas |= ([([2,.] | max), ([2, '$count_nonspecific_nodes'] | max)] | min)'
    fi
  fi

  ###
  # Policy #3: don't run more than one kube-dns on single node
  fltr=$fltr' | .spec.template.spec.affinity.podAntiAffinity.preferredDuringSchedulingIgnoredDuringExecution = ((.spec.template.spec.affinity.podAntiAffinity.preferredDuringSchedulingIgnoredDuringExecution // []) + [{"weight":100,"podAffinityTerm":{"labelSelector":{"matchLabels":{"k8s-app":"kube-dns"}},"topologyKey":"kubernetes.io/hostname"}}] | unique)'

  # wipe empty fields
  fltr=$fltr' | .spec.template.spec.affinity |= remove_empty'

  kubernetes::patch_jq kube-system deployment/$(context::get snapshots.kube_dns.0.object.metadata.name) "$fltr"
}

hook::run $@
