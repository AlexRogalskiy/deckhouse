#!/bin/bash

set -Eeuo pipefail
shopt -s inherit_errexit
shopt -s failglob

set -x

# Base env
CLUSTER_PKI_DIR=/pki
CONFIG_DIR=/config
ROOTFS_DIR=
BASE_DIR=$ROOTFS_DIR/etc/kubernetes/deckhouse
CLUSTER_CONFIGURATION_FILE=/etc/kubernetes/deckhouse/kubeadm-config.yaml
LAST_APPLIED_CLUSTER_CONFIGURATION_CHECKSUM_FILE=$BASE_DIR/last_applied_cluster_configuration_checksum
LAST_APPLIED_CLUSTER_CONFIGURATION_CHECKSUM=""
if [[ -f $LAST_APPLIED_CLUSTER_CONFIGURATION_CHECKSUM_FILE ]] ; then
  LAST_APPLIED_CLUSTER_CONFIGURATION_CHECKSUM=$(cat $LAST_APPLIED_CLUSTER_CONFIGURATION_CHECKSUM_FILE)
fi

function generate_kubeadm_config() {
  # Generate cluster config for current node
  gomplate \
    -c "clusterConfiguration=file:///${CONFIG_DIR}/cluster-configuration.json" \
    -c "nodeIP=env:///MY_IP" \
    -c "extraArgs=env:///KUBEADM_EXTRA_ARGS?type=application/json" \
    -f "$CONFIG_DIR/kubeadm-config.yaml.tpl" \
    -o "$ROOTFS_DIR/$CLUSTER_CONFIGURATION_FILE"
}

function backup_file_or_folder() {
  if [[ ! -e $BACKUP_DIR/$1 ]] ; then
    mkdir -m go= -p $(dirname $BACKUP_DIR/$1)
    echo " * Backup $ROOTFS_DIR/etc/kubernetes/$1 (to $BACKUP_DIR/$1)"
    cp -a $ROOTFS_DIR/etc/kubernetes/$1 $BACKUP_DIR/$1
  fi
}

function install_file_if_changed() {
  src=$1; shift
  dst=$1; shift

  if cmp -s $src $ROOTFS_DIR/etc/kubernetes/$dst ; then
    echo " * File $ROOTFS_DIR/etc/kubernetes/$dst has not changed"
  else
    if [[ -e $ROOTFS_DIR/etc/kubernetes/$dst ]] ; then
      backup_file_or_folder $dst
    fi

    echo " * Install $ROOTFS_DIR/etc/kubernetes/$dst"
    install $@ $src $ROOTFS_DIR/etc/kubernetes/$dst
  fi
}

function certificate_valid_for() {
  not_after=$(cfssl-certinfo -cert - | jq .not_after -r | sed 's/\([0-9]\{4\}-[0-9]\{2\}-[0-9]\{2\}\)T\([0-9]\{2\}:[0-9]\{2\}:[0-9]\{2\}\).*/\1 \2/')
  expr $(date --date="$not_after" +%s) - $(date +%s)
}

function generate_or_renew_certificate() {
  certificate=$1
  file=$1
  if [[ $# -gt 1 ]] ; then
    file=$2
  fi

  echo "Generate or renew certificate $certificate ($file.crt)"
  if [[ -f $ROOTFS_DIR/etc/kubernetes/pki/$file.crt ]] ; then
    valid_for=$(cat $ROOTFS_DIR/etc/kubernetes/pki/$file.crt | certificate_valid_for)

    remove="no"
    if [[ "$CLUSTER_CONFIGURATION_CHECKSUM" != "$LAST_APPLIED_CLUSTER_CONFIGURATION_CHECKSUM" ]] ; then
      echo " * Cluster configuration has changed since last certificate generation"
      remove="yes"
    fi

    if [[ "$valid_for" -lt 2592000 ]] ; then
      echo " * Certificate is expiring in less than 30 days"
      remove="yes"
    else
      echo " * Certificate is valid for more than $(expr $valid_for / 86400) days"
    fi

    if [[ ! -f $ROOTFS_DIR/etc/kubernetes/pki/$file.key ]] ; then
      echo " * Certificate exists, but no key found"
      remove="yes"
    fi

    if [[ "x$remove" == "xyes" ]] ; then
      if [[ -f $ROOTFS_DIR/etc/kubernetes/pki/$file.key ]] ; then
        backup_file_or_folder pki/$file.key
        echo " * Remove $ROOTFS_DIR/etc/kubernetes/pki/$file.key"
        rm -rf $ROOTFS_DIR/etc/kubernetes/pki/$file.key
      fi

      backup_file_or_folder pki/$file.crt
      echo " * Remove $ROOTFS_DIR/etc/kubernetes/pki/$file.crt"
      rm -rf $ROOTFS_DIR/etc/kubernetes/pki/$file.crt
    fi
  fi

  if [[ ! -f $ROOTFS_DIR/etc/kubernetes/pki/$file.crt ]] ; then
    echo " * Generate new certificate"
    kubeadm init phase certs $certificate --config $CLUSTER_CONFIGURATION_FILE --rootfs "$ROOTFS_DIR"
  fi
  echo " * Done!"
}

function generate_or_renew_kubeconfig() {
  kubeconfig=$1

  echo "Generate or renew $kubeconfig kubeconfig"
  if [[ -f $ROOTFS_DIR/etc/kubernetes/$kubeconfig.conf ]] ; then
    cert="$(kubectl config view -o json --raw | jq '.users[0].user."client-certificate-data"' -r | base64 -d)"
    valid_for=$(echo "$cert" | certificate_valid_for)

    remove="no"
    if [[ "$CLUSTER_CONFIGURATION_CHECKSUM" != "$LAST_APPLIED_CLUSTER_CONFIGURATION_CHECKSUM" ]] ; then
      echo " * Cluster configuration has changed since last kubeconfig generation"
      remove="yes"
    fi

    if [[ "$valid_for" -lt 2592000 ]] ; then
      echo " * Certificate is expiring in less than 30 days"
      remove="yes"
    else
      echo " * Certificate is valid for more than $(expr $valid_for / 86400) days"
    fi

    if [[ "x$remove" == "xyes" ]] ; then
      backup_file_or_folder $kubeconfig.conf
      echo " * Remove $ROOTFS_DIR/etc/kubernetes/$kubeconfig.conf"
      rm -rf $ROOTFS_DIR/etc/kubernetes/$kubeconfig.conf
    fi
  fi

  if [[ ! -f $ROOTFS_DIR/etc/kubernetes/$kubeconfig.conf ]] ; then
    echo " * Generate new kubeconfig"
    kubeadm init phase kubeconfig $kubeconfig --config $CLUSTER_CONFIGURATION_FILE --rootfs "$ROOTFS_DIR"
  fi

  echo " * Done!"
}

function converge_component() {
  component=$1

  echo "Converge $component"

  # Update component extra files, if present
  mkdir -p -m go= $BASE_DIR/${component}-files
  config_extra_files_checksums=""
  if [[ "x$(ls -1 $CONFIG_DIR | grep file-${component})" != "x" ]] ; then
    config_extra_files_checksums="$(sha256sum $CONFIG_DIR/file-${component}-* | cut -d " " -f 1 | sort)"
  fi
  actual_extra_files_checksums=""
  if [[ "x$(ls -1 $BASE_DIR/${component}-files)" != "x" ]] ; then
    actual_extra_files_checksums="$(sha256sum $BASE_DIR/${component}-files/* | cut -d " " -f 1 | sort)"
  fi
  if [[ "x$config_extra_files_checksums" != "x$actual_extra_files_checksums" ]] ; then
    if [[ "x$actual_extra_files_checksums" != "x" ]] ; then
      backup_file_or_folder deckhouse/${component}-files
      echo " * Remove $BASE_DIR/${component}-files/*"
      rm -f $BASE_DIR/${component}-files/*
    fi

    if [[ "x$config_extra_files_checksums" != "x" ]] ; then
      for file in $(cd $CONFIG_DIR; ls -1 file-${component}-*) ; do
        echo " * Copy $CONFIG_DIR/$file to $BASE_DIR/${component}-files/${file#file-${component}-}"
        cp $CONFIG_DIR/$file $BASE_DIR/${component}-files/${file#file-${component}-}
      done
    fi
  else
    echo " * Skip extra files synchronization because they are in sync"
  fi

  # Calculate checksum
  checksum_dependencies="$(find $ROOTFS_DIR/etc/kubernetes/pki/ $ROOTFS_DIR/etc/kubernetes/scheduler.conf $ROOTFS_DIR/etc/kubernetes/controller-manager.conf $ROOTFS_DIR/$CLUSTER_CONFIGURATION_FILE $BASE_DIR/${component}-files -type f)"
  checksum=$(sha256sum $(echo $checksum_dependencies) | sha256sum | cut -d" " -f1)

  if [[ ! -f $ROOTFS_DIR/etc/kubernetes/manifests/$component.yaml ]] || ! grep $checksum $ROOTFS_DIR/etc/kubernetes/manifests/$component.yaml > /dev/null ; then
    # Generate patches for kustomize
    if [[ -d $BASE_DIR/kustomize/$component ]] ; then
      rm -rf $BASE_DIR/kustomize/$component
    fi
    mkdir -p $BASE_DIR/kustomize/$component
    component_image_var_name=$(echo $component | tr '[:lower:]-' '[:upper:]_')_IMAGE
    cat > $BASE_DIR/kustomize/$component/01_image_and_checksum.yaml <<END
apiVersion: v1
kind: Pod
metadata:
  name: $component
  namespace: kube-system
  annotations:
    control-plane-manager.deckhouse.io/checksum: "$checksum"
spec:
  containers:
  - name: $component
    image: ${!component_image_var_name}
END
    if [[ "x$config_extra_files_checksums" != "x" ]] ; then
      cat > $BASE_DIR/kustomize/$component/02_extra_files.yaml <<END
apiVersion: v1
kind: Pod
metadata:
  name: $component
  namespace: kube-system
spec:
  containers:
  - name: $component
    volumeMounts:
    - mountPath: ${BASE_DIR}/${component}-files/
      name: deckhouse-files
      readOnly: true
  volumes:
  - hostPath:
      path: ${BASE_DIR}/${component}-files/
      type: DirectoryOrCreate
    name: deckhouse-files
END
    fi

    # Generate new manifest
    if [[ -f $ROOTFS_DIR/etc/kubernetes/manifests/$component.yaml ]] ; then
      backup_file_or_folder manifests/$component.yaml
    fi
    if [[ "x$component" != "xetcd" ]] ; then
      kubeadm init phase control-plane ${component#kube-} --config $CLUSTER_CONFIGURATION_FILE --rootfs "$ROOTFS_DIR" --experimental-kustomize /etc/kubernetes/deckhouse/kustomize/$component
    else
      # Process etcd
      if [[ ! -f /var/lib/etcd/member/snap/db ]] ; then
        # Bootstrap etcd, if there is no /var/lib/etcd/member/snap/db

        etcd_endpoints=$(timeout 10 kubectl -n kube-system get pod -l component=etcd,tier=control-plane -o json | jq '[.items[] | "https://" + .status.podIP + ":2379"] | join(",")' -r)
        etcd_env=$(ETCDCTL_API=3 etcdctl member add "${HOSTNAME}" --peer-urls="https://${MY_IP}:2380" \
          --endpoints $etcd_endpoints \
          --cacert $ROOTFS_DIR/etc/kubernetes/pki/etcd/ca.crt \
          --cert $ROOTFS_DIR/etc/kubernetes/pki/etcd/ca.crt \
          --key $ROOTFS_DIR/etc/kubernetes/pki/etcd/ca.key | grep ^ETCD_)

        eval "$etcd_env"
        KUBEADM_EXTRA_ARGS="{\"etcd\":{\"initial-cluster\": \"$ETCD_INITIAL_CLUSTER\", \"initial-cluster-state\": \"$ETCD_INITIAL_CLUSTER_STATE\"}}"
        export KUBEADM_EXTRA_ARGS

        generate_kubeadm_config
      fi

      kubeadm init phase etcd local --config $CLUSTER_CONFIGURATION_FILE --rootfs "$ROOTFS_DIR" --experimental-kustomize /etc/kubernetes/deckhouse/kustomize/$component
    fi
  else
    echo " * Skip manifest generation because component checksum in manifest is up to date"
  fi

  # Wait up to 4 mins
  echo " * Wait for pod with new manifest to become ready in apiserver"
  n=0
  while true ; do
    if ! timeout 10 kubectl version > /dev/null 2> /dev/null ; then
      echo "    * No access to apiserver"
    elif pod=$(timeout 10 kubectl -n kube-system get pod $component-$HOSTNAME -o json 2> /dev/null) ; then
      pod_checksum=$(echo "$pod" | jq '.metadata.annotations."control-plane-manager.deckhouse.io/checksum"' -r 2> /dev/null)

      if [[ "x$pod_checksum" != "x$checksum" ]] ; then
        echo "    * Checksum from kubernetes pod $component-$HOSTNAME ($pod_checksum) does not match expected checksum ($checksum)"
      else
        if echo "$pod" | jq '.status.conditions[] | select(.type == "Ready") | .status == "True"' 2> /dev/null > /dev/null ; then
          echo "    * Pod has matching checksum and is ready"
          break
        else
          echo "    * Pod has matching checksum but is not ready"
        fi
      fi
    else
      echo "    * Failed to get pod $component-$HOSTNAME from apiserver"
    fi

    n=$((n + 1))
    if [[ $n -gt 240 ]] ; then
      echo "    * Fatal error: Timeout waiting for pod $component-$HOSTNAME to become ready with expected checksum ($checksum)"
      exit 1
    fi

    sleep 1
  done

  echo " * Done!"
  echo
}

# Create base dir
mkdir -p $BASE_DIR

# Generate config
if [[ "x$MY_IP" == "x" ]] ; then
  echo "Fatal error: \$MY_IP is empty"
  exit 1
fi
KUBEADM_EXTRA_ARGS="{}"
export KUBEADM_EXTRA_ARGS
generate_kubeadm_config
CLUSTER_CONFIGURATION_CHECKSUM=$(cat ${BASH_SOURCE[0]} $ROOTFS_DIR/$CLUSTER_CONFIGURATION_FILE | sha256sum | cut -d" " -f1)
BACKUP_DIR=$BASE_DIR/backup/$CLUSTER_CONFIGURATION_CHECKSUM

# Install base pki into system
echo "Install base pki files"
mkdir -p $ROOTFS_DIR/etc/kubernetes/pki
for f in ca.crt front-proxy-ca.crt ; do
  install_file_if_changed $CLUSTER_PKI_DIR/$f pki/$f -o root -g root -m 0644
done
for f in ca.key sa.pub sa.key front-proxy-ca.key ; do
  install_file_if_changed $CLUSTER_PKI_DIR/$f pki/$f -o root -g root -m 0600
done
mkdir -p $ROOTFS_DIR/etc/kubernetes/pki/etcd
install_file_if_changed $CLUSTER_PKI_DIR/etcd-ca.crt pki/etcd/ca.crt -o root -g root -m 0644
install_file_if_changed $CLUSTER_PKI_DIR/etcd-ca.key pki/etcd/ca.key -o root -g root -m 0600
echo " * Done!"
echo

# Process all certificates
generate_or_renew_certificate apiserver
generate_or_renew_certificate apiserver-kubelet-client
generate_or_renew_certificate apiserver-etcd-client
generate_or_renew_certificate front-proxy-client
generate_or_renew_certificate etcd-server etcd/server
generate_or_renew_certificate etcd-peer etcd/peer
generate_or_renew_certificate etcd-healthcheck-client etcd/healthcheck-client
echo

# Process all kubeconfig's
generate_or_renew_kubeconfig admin
generate_or_renew_kubeconfig controller-manager
generate_or_renew_kubeconfig scheduler
echo

# Update root kubeconfig
echo "Update root user kubeconfig (/root/.kube/config)"
if [[ ! -f /root/.kube/config ]] || ! cmp -s $ROOTFS_DIR/root/.kube/config $ROOTFS_DIR/etc/kubernetes/admin.conf ; then
  echo " * Create symlink from $ROOTFS_DIR/etc/kubernetes/admin.conf to $ROOTFS_DIR/root/.kube/config"
  ln -fs $ROOTFS_DIR/etc/kubernetes/admin.conf $ROOTFS_DIR/root/.kube/config
else
  echo " * Root kubeconfig is up to date"
fi
echo " * Done!"
echo

# Process components
converge_component etcd
converge_component kube-apiserver
converge_component kube-controller-manager
converge_component kube-scheduler

# Save last applied cluster configuration checksum
echo "$CLUSTER_CONFIGURATION_CHECKSUM" > $LAST_APPLIED_CLUSTER_CONFIGURATION_CHECKSUM_FILE

# Remove backup
echo "Remove backup"
if [[ -d $BACKUP_DIR ]] ; then
  rm -rf $BACKUP_DIR
fi
echo " * Done!"
echo


echo "Successfully finished!!!"
touch /ready

exec /pause
