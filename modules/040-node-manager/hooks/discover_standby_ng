#!/bin/bash

source /deckhouse/shell_lib.sh

function __config__() {
  cat << EOF
    configVersion: v1
    kubernetes:
    - name: node_groups
      apiVersion: deckhouse.io/v1alpha1
      kind: NodeGroup
      group: main
      keepFullObjectsInMemory: false
      queue: /modules/$(module::name::kebab_case)/discover_standby_ng
      jqFilter: |
        {
          "name": .metadata.name,
          "maxInstances": ((.spec.cloudInstances.zones // ["defaultZone"] | length) * (.spec.cloudInstances.maxPerZone // 1)),
          "standby": (.spec.cloudInstances.standby // null),
          "standbyNotHeldResources": (.spec.cloudInstances.standbyHolder.notHeldResources // {}),
          "taints": (.spec.nodeTemplate.taints // [])
        }
    - name: nodes
      group: main
      keepFullObjectsInMemory: false
      queue: /modules/$(module::name::kebab_case)/discover_standby_ng
      apiVersion: v1
      kind: Node
      jqFilter: |
        {
          "group": .metadata.labels."node.deckhouse.io/group",
          # .status.allocatable represents all available resources, not the only remaining.
          "allocatableCPU": .status.allocatable.cpu,
          "allocatableMemory": .status.allocatable.memory,
          "isReady": ([(.status.conditions // [])[] | select(.type == "Ready" and .status == "True")] | length > 0),
          "isUnschedulable": (.spec.unschedulable // false)
        }
    - name: standby_pods
      apiVersion: v1
      kind: Pod
      group: main
      keepFullObjectsInMemory: false
      queue: /modules/$(module::name::kebab_case)/discover_standby_ng
      labelSelector:
        matchExpressions:
        - key: app
          operator: In
          values:
          - standby-holder
      namespace:
        nameSelector:
          matchNames: [d8-cloud-instance-manager]
      jqFilter: |
        {
          "group": .metadata.labels.ng,
          "isReady": ([(.status.conditions // [])[] | select(.type == "Ready" and .status == "True")] | length > 0)
        }
EOF
}


# $1 — NG name
# $2 — standby nodes count or empty
function _set_ng_standby_status() {
  if [ -n "$2" ]; then
    status_patch="$(jq -n --argjson count "$2" '{"standby": $count}')"
  else
    status_patch="$(jq -n '{"standby": null}')"
  fi
  kubernetes::status::merge_patch "" "deckhouse.io/v1alpha1" "nodegroups" "${1}" "${status_patch}"
}

function __main__() {
  standby_node_groups="[]"

  for i in $(context::jq -r '.snapshots.node_groups | keys[]'); do
    ng=$(context::get snapshots.node_groups.$i.filterResult)
    ng_name=$(jq -r '.name' <<< "$ng")

    if ! standby=$(jq -er 'select(.standby) | .standby' <<< "$ng"); then
      _set_ng_standby_status "${ng_name}" ""
      continue
    fi

    max_instances=$(jq -r '.maxInstances' <<< "$ng")

    if [[ $standby =~ ^[0-9]+%$ ]]; then
      percent=$(echo "$standby" | sed -r 's/[^0-9]+//g')
      desired_standby=$((max_instances*percent/100))
    else
      desired_standby=$standby
    fi

    # Running standby Pods count - representing Running standby Nodes count.
    standby_nodes_count=$(context::jq -r --arg ng_name "$ng_name" '[.snapshots.standby_pods[].filterResult | select(.group == $ng_name and .isReady == true)] | length')
    _set_ng_standby_status "${ng_name}" "${standby_nodes_count}"

    ready_nodes_count=$(context::jq -r --arg ng_name "$ng_name" '[.snapshots.nodes[].filterResult | select(.group == $ng_name and .isReady == true and .isUnschedulable == false)] | length')
    duty_nodes_count=$((ready_nodes_count-standby_nodes_count))
    total_nodes_count=$((duty_nodes_count+desired_standby))
    if (( total_nodes_count > max_instances )); then
      excess_nodes_count=$((total_nodes_count-max_instances))
      desired_standby=$((desired_standby-excess_nodes_count))
    fi

    # Always keep one Pending standby Pod to catch a Node on application scale down.
    if (( desired_standby <= 0 )); then
      desired_standby=1
    fi

    allocatable_cpu="$(tools::dk_convert --milli "$(context::jq -r --arg ng_name "$ng_name" '[.snapshots.nodes[].filterResult | select(.group == $ng_name and .allocatableCPU) | .allocatableCPU] | sort | first // 0')")"
    resources_requests_every_node_cpu="$(tools::dk_convert --milli "$(values::get --required "global.modules.resourcesRequests.everyNode.cpu")")"
    standby_not_held_resources_cpu="$(tools::dk_convert --milli "$(jq -r '.standbyNotHeldResources.cpu // 0' <<< "$ng")")"
    standby_request_cpu=$(( allocatable_cpu - (resources_requests_every_node_cpu + standby_not_held_resources_cpu) ))
    # Request at least 10m of cpu.
    if (( standby_request_cpu < 10 )); then
      standby_request_cpu="10"
    fi
    standby_request_cpu="${standby_request_cpu}m"

    allocatable_memory="$(tools::dk_convert "$(context::jq -r --arg ng_name "$ng_name" '[.snapshots.nodes[].filterResult | select(.group == $ng_name and .allocatableMemory) | .allocatableMemory] | sort | first // 0')")"
    resources_requests_every_node_memory="$(tools::dk_convert "$(values::get --required "global.modules.resourcesRequests.everyNode.memory")")"
    standby_not_held_resources_memory="$(tools::dk_convert "$(jq -r '.standbyNotHeldResources.memory // 0' <<< "$ng")")"
    standby_request_memory=$(( allocatable_memory - (resources_requests_every_node_memory + standby_not_held_resources_memory) ))
    # Convert to Mi.
    standby_request_memory=$((standby_request_memory/1024/1024))
    # Request at least 10Mi of memory.
    if (( standby_request_memory < 10 )); then
      standby_request_memory="10"
    fi
    standby_request_memory="${standby_request_memory}Mi"

    standby_node_groups="$(jq \
      --argjson ng "$ng" \
      --arg desired_standby "$desired_standby" \
      --arg standby_request_cpu "$standby_request_cpu" \
      --arg standby_request_memory "$standby_request_memory" '
      . + [$ng |
        {
          "name": .name,
          "standby": $desired_standby | tonumber,
          "reserveCPU": $standby_request_cpu,
          "reserveMemory": $standby_request_memory,
          "taints": .taints
        }
      ]' <<< $standby_node_groups)"
  done

  values::set nodeManager.internal.standbyNodeGroups "$standby_node_groups"
}

hook::run "$@"
